{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ebec05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from transformers import MimiModel, AutoFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31384e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from overfit_trial.data_models import (\n",
    "    MimiChannelArchive,\n",
    ")\n",
    "from overfit_trial.model import MachOverfitModel\n",
    "from overfit_trial.inference import SlidingDuplexModelInference\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d4f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_FREQ = 12.5\n",
    "num_quantizers = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e31948",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mimi = MimiModel.from_pretrained(\"kyutai/mimi\", num_quantizers=num_quantizers)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"kyutai/mimi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba17a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def offload_after_context():\n",
    "    gpu_tensors = []\n",
    "\n",
    "    class Tracker:\n",
    "        def to(self, device):\n",
    "            # Intercept `.to('cuda')` calls\n",
    "            tensor = self.tensor.to(device)\n",
    "            if device.startswith(\"cuda\"):\n",
    "                gpu_tensors.append(tensor)\n",
    "            return tensor\n",
    "\n",
    "        def __init__(self, tensor):\n",
    "            self.tensor = tensor\n",
    "\n",
    "    try:\n",
    "        yield Tracker  # gives you a class that wraps tensors\n",
    "    finally:\n",
    "        for t in gpu_tensors:\n",
    "            t.cpu()\n",
    "        gpu_tensors.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cf8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id_pair = [\"V00_S0696_I00000375_P0844A\", \"V00_S0696_I00000375_P0847\"]\n",
    "num_quantizers = 32\n",
    "SAMPLE_RATE_HZ = 24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4e40e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_root = Path(os.getcwd()).parent\n",
    "\n",
    "channel1 = MimiChannelArchive(\n",
    "    channel_id=channel_id_pair[0],\n",
    "    npz_path=Path(repo_root / \"asset\" / \"single_pair_dataset\" / f\"{channel_id_pair[0]}.{num_quantizers}q.npz\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32f10dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = channel1.load_codes()\n",
    "user_codes = user.to_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053f386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with offload_after_context() as Tracker:\n",
    "    model_output = mimi.decode(user_codes.unsqueeze(0))\n",
    "    user_audio = model_output.audio_values.detach().cpu().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25964bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(user_audio[: 24000 * 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21843902",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_frame = 0\n",
    "warmp_up_seconds = 2\n",
    "warmup_frames = int(LATENT_FREQ * warmp_up_seconds)\n",
    "decode_seconds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa473d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplex_checkpoint = \"/home/henry/dev/overfit-duplex/checkpoints/overfit_trial/checkpoint_update_500.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77508e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplex = MachOverfitModel(\n",
    "    num_quantizers=32, mimi_audio_embed_dir=\"/home/henry/dev/overfit-duplex/asset/mimi_audio_embeddings\"\n",
    ")\n",
    "engine = SlidingDuplexModelInference(duplex, num_quantizers=32, window_size=512, device=\"cuda\")\n",
    "engine.load_checkpoint(duplex_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6448a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = engine.generate(\n",
    "    user_codes=user_codes.to(device),\n",
    "    start_frame=start_frame,\n",
    "    warmup_frames=warmup_frames,\n",
    "    num_steps=int(LATENT_FREQ * decode_seconds),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b77ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with offload_after_context() as Tracker:\n",
    "    model_output = mimi.decode(result.cpu())\n",
    "    audio_arr = model_output.audio_values.detach().cpu().squeeze().numpy()\n",
    "full_assistant_audio = np.concatenate([np.zeros(24000 * warmp_up_seconds), audio_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_user = user_audio[int(LATENT_FREQ * start_frame) : full_assistant_audio.shape[0]]\n",
    "assert full_user.shape == full_assistant_audio.shape\n",
    "full_convo = full_user + full_assistant_audio\n",
    "Audio(full_convo, rate=24000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
